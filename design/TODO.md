

## Scanning

- Cost monitoring / limits
- General performance


- Use generate cache?

## LLM Scanner

- Chunking of long transcripts into multiple pieces
- Using multiple models with some consolidation


- apply_scores from results database

- loader takes the transcript database
- scanner can take groups of transcripts (chunking)

