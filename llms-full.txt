# Inspect Scout


## Welcome

Welcome to Inspect Scout, a tool for in-depth analysis of AI agent
transcripts. Scout is built to work with transcripts from the [Inspect
AI](https://inspect.aisi.org.uk/) evaluation framework, and has the
following core features:

1.  Scan full sample transcripts or individual messages or events.
2.  High performance parallel processing of transcript content.
3.  Resume scans that are stopped due to errors or interruptions.
4.  Tightly integrated with Inspect [data
    frames](https://inspect.aisi.org.uk/dataframe.html) for input and
    analysis.

### Installation

Install the `inspect_scout` package from GitHub as follows:

``` bash
pip install git+https://github.com/meridianlabs-ai/inspect_scout
```

Inspect Scout also depends on the development version of Inspect AI,
which will be installed automatically when you install Scout.

## Scout Basics

> [!CAUTION]
>
> The code below is intended to illustrate the basic API and usage of
> Scout. However, the code doesn’t currently work! For the time being
> please use this for design review only rather than direct
> experimentation.

Below we’ll provide some simple examples of creating and using Scout
scanners. Some core components we’ll make use of here include:

- `Transcript` — LLM conversation to analyze (e.g. an Inspect sample
  trajectory).

- `Scanner` — Function that takes an input from a `Transcript` and
  returns a `Result` (conceptually very similar to an Inspect `Scorer`).

- `Results` — Data frame(s) that includes the results of scanners
  applied to transcripts.

### Creating a Scanner

The following illustrates the implementation of a simple LLM scanner
(click on the numbers at right for further explanation):

**scanner.py**

``` python
from inspect_scout import (
    Result, Scanner, Transcript, scanner, messages_as_str
)

from inspect_ai.model import get_model

@scanner(messages="all")
def ctf_environment() -> Scanner[Transcript]:
    
    async def scan(transcript: Transcript) -> Result:

        # call model
        result = await get_model().generate(
            "Here is a transcript of an LLM agent " +
            "solving a cybersecurity challenge:\n\n" +
            "===================================" +
            messages_as_str(transcript.messages) +
            "===================================\n\n" +
            "In the transcript above do you detect any " +
            "instances of environment misconfiguration " +
            "preventing the agent from completing it's " + 
            "task? If no, simply respond with 'No'. " +
            "If yes, respond with 'Yes' followed by an " +
            "explanation."
        )

        # extract value (None indicates nothing found)
        if result.completion.lower().startswith("yes"):
            value = True
        else:
            value = None

        # return result (value + full model completion)
        return Result(
            value=value,
            explanation=result.completion
        )

    return scan
```

Line 7  
Scanners are decorated with `@scanner` so they can specify the exact
subset of content they need to read. In this case only messages (and not
events) will be read from the log, decreasing load time.

Line 13  
Scanners frequently use models to perform scanning. Calling
`get_model()` utilizes the default model for the scan job (which can be
specified in the top level call to scan).

Lines 16-18  
Convert the message history into a string for presentation to the model.

Lines 27-31  
Scanners are looking for particular content or behavior and by
convention return a `None` value when the target isn’t found.

Lines 34-37  
As with scorers, results also include additional context (here the full
model completion).

> [!NOTE]
>
> ### Scanner Results
>
> One important concept illustrated above is handling of `Result` return
> values from scanners. The nature of most scanners is that they are
> looking for something in particular—if they don’t find it then their
> return value is effectively `None` (nothing to see here). That said,
> you may still want to capture contextual information about the scan
> (e.g. the model’s output). Therefore, the convention is to return
> `Result(value=None)` in cases where the scanner didn’t find what it
> was looking for.

### Running a Scan

We can now run that scanner on our log files. The `Scanner` will be
called once for each sample trajectory in the log (total samples \*
epochs):

``` bash
scout scan scanner.py --transcripts ./logs -model openai/gpt-5
```

### Adding a Scanner

Let’s add another scanner that looks for uses of Java in tool calls:

``` python
@scanner(events=["tool"]) 
def java_tool_usages() -> Scanner[ToolEvent]:
    
    async def scan(event: ToolEvent) -> Result:
        if "java" in str(event.arguments).lower():
            return Result(
                value=True, 
                explanation=str(event.arguments)
            )
        else:
            return Result(value=None)
       
    return scan
```

Note that we specify `events=["tool"]` to constrain reading to only tool
events, and that our function takes an individual event rather than a
`Transcript`.

If you add this scanner to the same source file as the
`ctf_environment()` scanner then `scout scan` will run both of the
scanners using the same `scout scan scanner.py` command,

### Scan Jobs

You may want to import scanners from other modules and compose them into
a `ScanJob`. To do this, add a `@scanjob` decorated function to your
source file (it will be used in preference to `@scanner` decorated
functions).

``` python
from inspect_scout import ScanJob, scanjob

@scanjob
def job() -> ScanJob:
    return ScanJob(
        scanners=[ctf_environment(), java_tool_usages()]
    )
```

You can then use the same command to run the job (`scout scan` will
prefer a @scanjob defined in a file to individual scanners):

``` bash
scout scan scanner.py --transcripts ./logs -model openai/gpt-5
```

### Scan Results

By default, the results of scans are written into the `./scans`
directory. You can override this using the `--results` option—both file
paths and S3 buckets are supported.

Each scan is stored in its own directory and has both metadata about the
scan (configuration, errors, summary of results) as well as parquet
files that contain the results. You can read the results either as a
dict of Pandas data frames or as a DuckDB database (there will be a
table for each scanner).

``` python
# results as pandas data frames
results = scan_results("scans/scan_id=iGEYSF6N7J3AoxzQmGgrZs")
deception_df = results.data["deception"]
tool_errors_df = results.data["tool_errors"]

# results as duckdb database 
results = scan_results_db("scans/scan_id=iGEYSF6N7J3AoxzQmGgrZs")
with results:
    # run queries to read data frames
    df = results.conn.execute("SELECT ...").fetch_df()

    # export entire database as file
    results.to_file("results.duckdb")
```

## Transcripts

In the example(s) above we scanned the samples from a single Inspect log
file. More commonly though you’ll target an entire log directory or a
subset of logs in that directory. For example, here we scan all of
Cybench logs in the `./logs` directory:

``` python
from inspect_scout (
    import scan, transcripts_from_logs, log_metadata as m
)

from .scanners import deception, tool_errors

transcripts = transcripts_from_logs("./logs")
transcripts = transcripts.where(m.task_name == "cybench")

status = scan(
    scanners = [ctf_environment(), tool_errors()],
    transcripts = transcripts
)
```

The `log_metadata` object (aliased to `m`) provides a typed way to
specified `where()` clauses for filtering transcripts.

Note that doing this query required us to switch to the Python `scan()`
API. We can still use the CLI if we wrap our transcript query in a
`ScanJob`:

**cybench_scan.py**

``` python
from inspect_scout (
    import ScanJob, scanjob, transcripts_from_logs, log_metadata as m
)

from .scanners import deception, tool_errors

@scanjob
def cybench_job(logs: str = "./logs") -> ScanJob:

    transcripts = transcripts_from_logs(logs)
    transcripts = transcripts.where(m.task_name == "cybench")

    return ScanJob(
        scanners = [deception(), java_tool_usages()],
        transcripts = transcripts
    )
```

Then from the CLI:

``` bash
scout scan cybench.py -S logs=./logs --model openai/gpt-5
```

The `-S` argument enables you to pass arguments to the `@scanjob`
function (in this case determining what directory to read logs from).

## Parallelism

The Scout scanning pipeline is optimized for parallel reading and
scanning as well as minimal memory consumption. There are a few options
you can use to tune parallelism:

| Option | Description |
|----|----|
| `--max-transcripts` | The maximum number of transcripts to scan in parallel (defaults to 25). You can set this higher if your model API endpoint can handle larger numbers of concurrent requests. |
| `--max-connections` | The maximum number of concurrent requests to the model provider (defaults to `--max-transcripts`). |
| `--max-processes` | The maximum number of processes to use for parsing and scanning (defaults to the number of CPUs on the system). |

## Learning More

See the following reference sections to learn more about using the Scout
API and CLI:

#### Python API

|  |  |
|----|----|
| [Scanning](./reference/scanning.qmd) | Scan transcripts and manage scan jobs. |
| [Results](./reference/results.qmd) | Status and results of scan jobs. |
| [Transcripts](./reference/scanner.qmd) | Read and filter transcripts. |
| [Scanners](./reference/scanner.qmd) | Implement scanners and loaders. |
| [Async](./reference/async.qmd) | Async functions for scanning. |

#### Scount CLI

|  |  |
|----|----|
| [scout scan](./reference/scout_scan.qmd) | Scan transcripts. |
| [scout scan resume](./reference/scout_scan.qmd#scout-scan-resume) | Resume a scan which is incomplete due to interruption or errors. |
| [scout scan complete](./reference/scout_scan.qmd#scout-scan-complete) | Complete a scan which is incomplete due to errors (errors are not retried). |
| [scout scan list](./reference/scout_scan.qmd#scout-scan-resume) | List the scans within a scan results directory. |

# Workflow



# Scanners



# Results



# Transcripts



# Parallelism



# Options



# Scanning


## Scanning

### scan

Scan transcripts.

Scan transcripts using one or more scanners. Note that scanners must
each have a unique name. If you have more than one instance of a scanner
with the same name, numbered prefixes will be automatically assigned.
Alternatively, you can pass tuples of (name,scanner) or a dict with
explicit names for each scanner.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L64)

``` python
def scan(
    scanners: Sequence[Scanner[ScannerInput] | tuple[str, Scanner[ScannerInput]]]
    | dict[str, Scanner[ScannerInput]]
    | ScanJob,
    transcripts: Transcripts | None = None,
    results: str | None = None,
    model: str | Model | None = None,
    model_config: GenerateConfig | None = None,
    model_base_url: str | None = None,
    model_args: dict[str, Any] | str | None = None,
    model_roles: dict[str, str | Model] | None = None,
    max_transcripts: int | None = None,
    max_processes: int | None = None,
    limit: int | None = None,
    shuffle: bool | int | None = None,
    tags: list[str] | None = None,
    metadata: dict[str, Any] | None = None,
    display: DisplayType | None = None,
    log_level: str | None = None,
) -> Status
```

`scanners` Sequence\[[Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\] \| tuple\[str, [Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\]\]\] \| dict\[str, [Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\]\] \| [ScanJob](scanning.qmd#scanjob)  
Scanners to apply to transcripts.

`transcripts` [Transcripts](transcript.qmd#transcripts) \| None  
Transcripts to scan.

`results` str \| None  
Location to write results (filesystem or S3 bucket). Defaults to
“./scans”.

`model` str \| Model \| None  
Model to use for scanning by default (individual scanners can always
call `get_model()` to us arbitrary models). If not specified use the
value of the SCOUT_SCAN_MODEL environment variable.

`model_config` GenerateConfig \| None  
`GenerationConfig` for calls to the model.

`model_base_url` str \| None  
Base URL for communicating with the model API.

`model_args` dict\[str, Any\] \| str \| None  
Model creation args (as a dictionary or as a path to a JSON or YAML
config file).

`model_roles` dict\[str, str \| Model\] \| None  
Named roles for use in `get_model()`.

`max_transcripts` int \| None  
The maximum number of transcripts to process concurrently (this also
serves as the default value for `max_connections`). Defaults to 25.

`max_processes` int \| None  
The maximum number of concurrent processes (for multiproccesing).
Defaults to `multiprocessing.cpu_count()`.

`limit` int \| None  
Limit the number of transcripts processed.

`shuffle` bool \| int \| None  
Shuffle the order of transcripts (pass an `int` to set a seed for
shuffling).

`tags` list\[str\] \| None  
One or more tags for this scan.

`metadata` dict\[str, Any\] \| None  
Metadata for this scan.

`display` DisplayType \| None  
Display type: “rich”, “plain”, or “none” (defaults to “rich”).

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

### scan_resume

Resume a previous scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L243)

``` python
def scan_resume(
    scan_location: str,
    display: DisplayType | None = None,
    log_level: str | None = None,
) -> Status
```

`scan_location` str  
Scan location to resume from.

`display` DisplayType \| None  
Display type: “rich”, “plain”, or “none” (defaults to “rich”).

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

### scan_complete

Complete a scan.

This function is used to indicate that a scan with errors in some
transcripts should be completed in spite of the errors.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L303)

``` python
def scan_complete(
    scan_location: str,
    display: DisplayType | None = None,
    log_level: str | None = None,
) -> Status
```

`scan_location` str  
Scan location to complete.

`display` DisplayType \| None  
Display type: “rich”, “plain”, or “none” (defaults to “rich”).

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

## Status

### Status

Status of scan job.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_recorder/recorder.py#L15)

``` python
@dataclass
class Status
```

#### Attributes

`complete` bool  
Is the job complete (all transcripts scanned).

`spec` ScanSpec  
Scan spec (transcripts, scanners, options).

`location` str  
Location of scan directory.

`summary` [Summary](results.qmd#summary)  
Summary of scan (results, errors, tokens, etc.)

`errors` list\[[Error](scanner.qmd#error)\]  
Errors during last scan attempt.

### ScanOptions

Options used for scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanspec.py#L44)

``` python
class ScanOptions(BaseModel)
```

#### Attributes

`max_transcripts` int  
Maximum number of concurrent transcripts (defaults to 25).

`max_processes` int  
Number of worker processes. Defaults to `multiprocessing.cpu_count()`.

`limit` int \| None  
Transcript limit (maximum number of transcripts to read).

`shuffle` bool \| int \| None  
Shuffle order of transcripts.

### ScanScanner

Scanner used by scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanspec.py#L18)

``` python
class ScanScanner(BaseModel)
```

#### Attributes

`name` str  
Scanner name.

`file` str \| None  
Scanner source file (if not in a package).

`params` dict\[str, Any\]  
Scanner arguments.

### ScanRevision

Git revision for scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanspec.py#L31)

``` python
class ScanRevision(BaseModel)
```

#### Attributes

`type` Literal\['git'\]  
Type of revision (currently only “git”)

`origin` str  
Revision origin server

`commit` str  
Revision commit.

### ScanTranscripts

Transcripts target by a scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanspec.py#L73)

``` python
class ScanTranscripts(BaseModel)
```

#### Attributes

`type` str  
Transcripts backing store type (currently only ‘eval_log’).

`fields` list\[[TranscriptField](scanning.qmd#transcriptfield)\]  
Data types of transcripts fields.

`count` int  
Trancript count.

`data` str  
Transcript data as a csv.

### TranscriptField

Field in transcript data frame.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanspec.py#L60)

``` python
class TranscriptField(TypedDict, total=False)
```

#### Attributes

`name` Required\[str\]  
Field name.

`type` Required\[str\]  
Field type (“integer”, “number”, “boolean”, “string”, or “datetime”)

`tz` NotRequired\[str\]  
Timezone (for “datetime” fields).

## Jobs

### scanjob

Decorator for registering scan jobs.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanjob.py#L103)

``` python
def scanjob(
    func: ScanJobType | None = None, *, name: str | None = None
) -> ScanJobType | Callable[[ScanJobType], ScanJobType]
```

`func` ScanJobType \| None  
Function returning `ScanJob`.

`name` str \| None  
Optional name for scanjob (defaults to function name).

### ScanJob

Scan job definition.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanjob.py#L28)

``` python
class ScanJob
```

#### Attributes

`name` str  
Name of scan job (defaults to @scanjob function name).

`transcripts` [Transcripts](transcript.qmd#transcripts) \| None  
Trasnscripts to scan.

`scanners` dict\[str, [Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\]\]  
Scanners to apply to transcripts.

# Transcript API


### transcripts_from_logs

Read sample transcripts from eval logs.

Logs can be specified by file or directory path(s) or alternatively an
[evals_df()](https://inspect.aisi.org.uk/reference/inspect_ai.analysis.html#evals_df)
or
[samples_df()](https://inspect.aisi.org.uk/reference/inspect_ai.analysis.html#evals_df)

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/database.py#L371)

``` python
def transcripts_from_logs(logs: LogPaths | pd.DataFrame) -> Transcripts
```

`logs` LogPaths \| pd.DataFrame  
Log paths as file(s), directories, or data frame.

### Transcripts

Collection of transcripts for scanning.

Transcript collections can be filtered using the `where()`, `limit()`,
and ’shuffle()\` methods. The transcripts are not modified in place so
the filtered transcripts should be referenced via the return value. For
example:

``` python
from inspect_scout import transcripts, log_metadata as m

transcripts = transcripts_from_logs("./logs")
transcripts = transcripts.where(m.task_name == "cybench")
```

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L13)

``` python
class Transcripts(abc.ABC)
```

#### Methods

where  
Filter the transcript collection by a `Condition`.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L35)

``` python
def where(self, condition: Condition) -> "Transcripts"
```

`condition` [Condition](transcript.qmd#condition)  
Filter condition.

limit  
Limit the number of transcripts processed.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L48)

``` python
def limit(self, n: int) -> "Transcripts"
```

`n` int  
Limit on transcripts.

shuffle  
Shuffle the order of transcripts.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L61)

``` python
def shuffle(self, seed: int | None = None) -> "Transcripts"
```

`seed` int \| None  
Random seed for shuffling.

count  
Number of transcripts in collection.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L87)

``` python
@abc.abstractmethod
async def count(self) -> int
```

index  
Index of `TranscriptInfo` for the collection.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/transcripts.py#L92)

``` python
@abc.abstractmethod
async def index(self) -> Iterator[TranscriptInfo]
```

### TranscriptInfo

Transcript identifier, location, and metadata.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/types.py#L36)

``` python
class TranscriptInfo(BaseModel)
```

#### Attributes

`id` str  
Globally unique id for transcript (e.g. sample uuid).

`source_id` str  
Globally unique ID for transcript source (e.g. eval_id).

`source_uri` str  
URI for source data (e.g. log file path)

`metadata` dict\[str, JsonValue\]  
e.g. eval config (model, scores, task params, etc.).

### Transcript

Transcript info and transcript content (messages and events).

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/types.py#L52)

``` python
class Transcript(TranscriptInfo)
```

#### Attributes

`messages` list\[ChatMessage\]  
Main message thread.

`events` list\[Event\]  
Events from transcript.

### Column

Database column with comparison operators.

Supports various predicate functions including `like()`, `not_like()`,
`between()`, etc. Additionally supports standard python equality and
comparison operators (e.g. `==`, ’\>\`, etc.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L521)

``` python
class Column
```

#### Methods

in\_  
Check if value is in a list.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L563)

``` python
def in_(self, values: list[Any]) -> Condition
```

`values` list\[Any\]  

not_in  
Check if value is not in a list.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L567)

``` python
def not_in(self, values: list[Any]) -> Condition
```

`values` list\[Any\]  

like  
SQL LIKE pattern matching (case-sensitive).

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L571)

``` python
def like(self, pattern: str) -> Condition
```

`pattern` str  

not_like  
SQL NOT LIKE pattern matching (case-sensitive).

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L575)

``` python
def not_like(self, pattern: str) -> Condition
```

`pattern` str  

ilike  
PostgreSQL ILIKE pattern matching (case-insensitive).

Note: For SQLite and DuckDB, this will use LIKE with LOWER() for
case-insensitivity.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L579)

``` python
def ilike(self, pattern: str) -> Condition
```

`pattern` str  

not_ilike  
PostgreSQL NOT ILIKE pattern matching (case-insensitive).

Note: For SQLite and DuckDB, this will use NOT LIKE with LOWER() for
case-insensitivity.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L586)

``` python
def not_ilike(self, pattern: str) -> Condition
```

`pattern` str  

is_null  
Check if value is NULL.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L593)

``` python
def is_null(self) -> Condition
```

is_not_null  
Check if value is not NULL.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L597)

``` python
def is_not_null(self) -> Condition
```

between  
Check if value is between two values.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L601)

``` python
def between(self, low: Any, high: Any) -> Condition
```

`low` Any  
Lower bound (inclusive). If None, raises ValueError.

`high` Any  
Upper bound (inclusive). If None, raises ValueError.

not_between  
Check if value is not between two values.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L615)

``` python
def not_between(self, low: Any, high: Any) -> Condition
```

`low` Any  
Lower bound (inclusive). If None, raises ValueError.

`high` Any  
Upper bound (inclusive). If None, raises ValueError.

### Condition

WHERE clause condition that can be combined with others.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L64)

``` python
class Condition
```

#### Methods

to_sql  
Generate SQL WHERE clause and parameters.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L116)

``` python
def to_sql(
    self,
    dialect: Union[
        SQLDialect, Literal["sqlite", "duckdb", "postgres"]
    ] = SQLDialect.SQLITE,
) -> tuple[str, list[Any]]
```

`dialect` Union\[SQLDialect, Literal\['sqlite', 'duckdb', 'postgres'\]\]  
Target SQL dialect (sqlite, duckdb, or postgres).

### Metadata

Entry point for building metadata filter expressions.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L630)

``` python
class Metadata
```

### metadata

Metadata selector for where expressions.

Typically aliased to a more compact expression (e.g. `m`) for use in
queries). For example:

``` python
from inspect_scout import metadata as m
filter = m.model == "gpt-4"
filter = (m.task_name == "math") & (m.epochs > 1)
```

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/metadata.py#L652)

``` python
metadata = Metadata()
```

### LogMetadata

Typed metadata interface for Inspect log transcripts.

Provides typed properties for standard Inspect log columns while
preserving the ability to access custom fields through the base Metadata
class methods.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/log.py#L10)

``` python
class LogMetadata(Metadata)
```

#### Attributes

`sample_id` [Column](transcript.qmd#column)  
Unique id for sample.

`eval_id` [Column](transcript.qmd#column)  
Globally unique id for eval.

`log` [Column](transcript.qmd#column)  
Location that the log file was read from.

`eval_created` [Column](transcript.qmd#column)  
Time eval was created.

`eval_tags` [Column](transcript.qmd#column)  
Tags associated with evaluation run.

`eval_metadata` [Column](transcript.qmd#column)  
Additional eval metadata.

`task_name` [Column](transcript.qmd#column)  
Task name.

`task_args` [Column](transcript.qmd#column)  
Task arguments.

`solver` [Column](transcript.qmd#column)  
Solver name.

`solver_args` [Column](transcript.qmd#column)  
Arguments used for invoking the solver.

`model` [Column](transcript.qmd#column)  
Model used for eval.

`generate_config` [Column](transcript.qmd#column)  
Generate config specified for model instance.

`model_roles` [Column](transcript.qmd#column)  
Model roles.

`id` [Column](transcript.qmd#column)  
Unique id for sample.

`epoch` [Column](transcript.qmd#column)  
Epoch number for sample.

`sample_metadata` [Column](transcript.qmd#column)  
Sample metadata.

`score` [Column](transcript.qmd#column)  
Headline score value.

`total_tokens` [Column](transcript.qmd#column)  
Total tokens used for sample.

`total_time` [Column](transcript.qmd#column)  
Total time that the sample was running.

`working_time` [Column](transcript.qmd#column)  
Time spent working (model generation, sandbox calls, etc.).

`error` [Column](transcript.qmd#column)  
Error that halted the sample.

`limit` [Column](transcript.qmd#column)  
Limit that halted the sample.

### log_metadata

Log metadata selector for where expressions.

Typically aliased to a more compact expression (e.g. `m`) for use in
queries). For example:

``` python
from inspect_scout import log_metadata as m

# typed access to standard fields
filter = m.model == "gpt-4"
filter = (m.task_name == "math") & (m.epochs > 1)

# dynamic access to custom fields
filter = m["custom_field"] > 100
```

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/log.py#L149)

``` python
log_metadata = LogMetadata()
```

# Scanner API


## Scanner

### Scanner

Scan transcript content.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/scanner.py#L67)

``` python
class Scanner(Protocol[T]):
    def __call__(self, input: T, /) -> Awaitable[Result]
```

`input` T  
Input to scan.

### ScannerInput

Union of all valid scanner input types.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/types.py#L11)

``` python
ScannerInput = Union[
    Transcript,
    ChatMessage,
    Sequence[ChatMessage],
    Event,
    Sequence[Event],
]
```

### Result

Scan result.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/result.py#L22)

``` python
class Result(BaseModel)
```

#### Attributes

`value` JsonValue  
Scan value (can be `None` if the scan didn’t find what is was looking
for).

`explanation` str \| None  
Explanation of result (optional).

`metadata` dict\[str, Any\] \| None  
Additional metadata related to the result (optional)

`references` list\[[Reference](scanner.qmd#reference)\]  
References to relevant messages or events.

### Reference

Reference to scanned content.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/result.py#L12)

``` python
class Reference(BaseModel)
```

#### Attributes

`type` Literal\['message', 'event'\]  
Reference type.

`id` str  
Reference id (message or event id)

### Error

Scan error (runtime error which occurred during scan).

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/result.py#L38)

``` python
class Error(BaseModel)
```

#### Attributes

`transcript_id` str  
Target transcript id.

`scanner` str  
Scanner name.

`error` str  
Error message.

`traceback` str  
Error traceback.

### Loader

Load transcript data.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/loader.py#L44)

``` python
class Loader(Protocol[TLoaderResult]):
    def __call__(
        self,
        transcript: Transcript,
    ) -> AsyncIterator[TLoaderResult]
```

`transcript` [Transcript](transcript.qmd#transcript)  
Transcript to yield from.

## Utils

### messages_as_str

Concatenate list of chat messages into a string.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/util.py#L15)

``` python
def messages_as_str(messages: list[ChatMessage]) -> str
```

`messages` list\[ChatMessage\]  
List of chat messages

## Types

### MessageType

Message types.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/types.py#L10)

``` python
MessageType = Literal["system", "user", "assistant", "tool"]
```

### EventType

Event types.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_transcript/types.py#L13)

``` python
EventType = Literal[
    "model",
    "tool",
    "approval",
    "sandbox",
    "info",
    "logger",
    "error",
    "span_begin",
    "span_end",
]
```

## Decorators

### scanner

Decorator for registering scanners.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/scanner.py#L179)

``` python
def scanner(
    factory: ScannerFactory[P, T] | None = None,
    *,
    loader: Loader[T] | None = None,
    messages: list[MessageType] | Literal["all"] | None = None,
    events: list[EventType] | Literal["all"] | None = None,
    name: str | None = None,
) -> (
    ScannerFactory[P, T]
    | Callable[[ScannerFactory[P, T]], ScannerFactory[P, T]]
    | Callable[[ScannerFactory[P, TM]], ScannerFactory[P, ScannerInput]]
    | Callable[[ScannerFactory[P, TE]], ScannerFactory[P, ScannerInput]]
)
```

`factory` ScannerFactory\[P, T\] \| None  
Decorated scanner function.

`loader` [Loader](scanner.qmd#loader)\[T\] \| None  
Custom data loader for scanner.

`messages` list\[[MessageType](scanner.qmd#messagetype)\] \| Literal\['all'\] \| None  
Message types to scan.

`events` list\[[EventType](scanner.qmd#eventtype)\] \| Literal\['all'\] \| None  
Event types to scan.

`name` str \| None  
Scanner name (defaults to function name).

### loader

Decorator for registering loaders.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanner/loader.py#L67)

``` python
def loader(
    *,
    name: str | None = None,
    messages: list[MessageType] | Literal["all"] | None = None,
    events: list[EventType] | Literal["all"] | None = None,
    content: TranscriptContent | None = None,
) -> Callable[[LoaderFactory[P, TLoaderResult]], LoaderFactory[P, TLoaderResult]]
```

`name` str \| None  
Loader name (defaults to function name).

`messages` list\[[MessageType](scanner.qmd#messagetype)\] \| Literal\['all'\] \| None  
Message types to load from.

`events` list\[[EventType](scanner.qmd#eventtype)\] \| Literal\['all'\] \| None  
Event types to load from.

`content` TranscriptContent \| None  
Transcript content filter.

# Async API


> [!NOTE]
>
> The Async API is available for async programs that want to use
> `inspect_scout` as an embedded library. Normal usage of Scout (e.g. in
> a script or notebook) should prefer the corresponding sync functions
> (e.g. `scan()`, `scan_resume().`, etc.)

### scan_async

Scan transcripts.

Scan transcripts using one or more scanners. Note that scanners must
each have a unique name. If you have more than one instance of a scanner
with the same name, numbered prefixes will be automatically assigned.
Alternatively, you can pass tuples of (name,scanner) or a dict with
explicit names for each scanner.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L138)

``` python
async def scan_async(
    scanners: Sequence[Scanner[ScannerInput] | tuple[str, Scanner[ScannerInput]]]
    | dict[str, Scanner[ScannerInput]]
    | ScanJob,
    transcripts: Transcripts | None = None,
    results: str | None = None,
    model: str | Model | None = None,
    model_config: GenerateConfig | None = None,
    model_base_url: str | None = None,
    model_args: dict[str, Any] | str | None = None,
    model_roles: dict[str, str | Model] | None = None,
    max_transcripts: int | None = None,
    max_processes: int | None = None,
    limit: int | None = None,
    shuffle: bool | int | None = None,
    tags: list[str] | None = None,
    metadata: dict[str, Any] | None = None,
    log_level: str | None = None,
) -> Status
```

`scanners` Sequence\[[Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\] \| tuple\[str, [Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\]\]\] \| dict\[str, [Scanner](scanner.qmd#scanner)\[[ScannerInput](scanner.qmd#scannerinput)\]\] \| [ScanJob](scanning.qmd#scanjob)  
Scanners to apply to transcripts.

`transcripts` [Transcripts](transcript.qmd#transcripts) \| None  
Transcripts to scan.

`results` str \| None  
Location to write results (filesystem or S3 bucket). Defaults to
“./scans”.

`model` str \| Model \| None  
Model to use for scanning by default (individual scanners can always
call `get_model()` to us arbitrary models). If not specified use the
value of the SCOUT_SCAN_MODEL environment variable.

`model_config` GenerateConfig \| None  
`GenerationConfig` for calls to the model.

`model_base_url` str \| None  
Base URL for communicating with the model API.

`model_args` dict\[str, Any\] \| str \| None  
Model creation args (as a dictionary or as a path to a JSON or YAML
config file).

`model_roles` dict\[str, str \| Model\] \| None  
Named roles for use in `get_model()`.

`max_transcripts` int \| None  
The maximum number of transcripts to process concurrently (this also
serves as the default value for `max_connections`). Defaults to 25.

`max_processes` int \| None  
The maximum number of concurrent processes (for multiproccesing).
Defaults to `multiprocessing.cpu_count()`.

`limit` int \| None  
Limit the number of transcripts processed.

`shuffle` bool \| int \| None  
Shuffle the order of transcripts (pass an `int` to set a seed for
shuffling).

`tags` list\[str\] \| None  
One or more tags for this scan.

`metadata` dict\[str, Any\] \| None  
Metadata for this scan.

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

### scan_resume_async

Resume a previous scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L263)

``` python
async def scan_resume_async(scan_location: str, log_level: str | None = None) -> Status
```

`scan_location` str  
Scan location to resume from.

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

### scan_complete_async

Complete a scan.

This function is used to indicate that a scan with errors in some
transcripts should be completed in spite of the errors.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scan.py#L327)

``` python
async def scan_complete_async(
    scan_location: str, log_level: str | None = None
) -> Status
```

`scan_location` str  
Scan location to complete.

`log_level` str \| None  
Level for logging to the console: “debug”, “http”, “sandbox”, “info”,
“warning”, “error”, “critical”, or “notset” (defaults to “warning”)

### scan_list_async

List completed and pending scans.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanlist.py#L19)

``` python
async def scan_list_async(scans_location: str) -> list[Status]
```

`scans_location` str  
Location of scans to list.

### scan_status_async

Status of scan.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanresults.py#L23)

``` python
async def scan_status_async(scan_location: str) -> Status
```

`scan_location` str  
Location to get status for (e.g. directory or s3 bucket)

### scan_results_async

Scan results as Pandas data frames.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanresults.py#L54)

``` python
async def scan_results_async(
    scan_location: str, *, scanner: str | None = None, include_null: bool = False
) -> Results
```

`scan_location` str  
Location of scan (e.g. directory or s3 bucket).

`scanner` str \| None  
Scanner name (defaults to all scanners).

`include_null` bool  
Should `None` results be included in the data frame (defaults to
`False`)

### scan_results_db_async

Scan results as DuckDB database.

[Source](https://github.com/meridianlabs-ai/inspect_scout/blob/927548064f72c27204f9e66803319623b4012eb5/src/inspect_scout/_scanresults.py#L86)

``` python
async def scan_results_db_async(
    scan_location: str, include_null: bool = False
) -> ResultsDB
```

`scan_location` str  
Location of scan (e.g. directory or s3 bucket).

`include_null` bool  
Should `None` results be included in the data frame (defaults to
`False`)

